{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54858298",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9acfd8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install plotly\n",
    "!pip install catboost\n",
    "!pip install skforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from joblib import dump, load\n",
    "from catboost import CatBoostRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02002cd2",
   "metadata": {},
   "source": [
    "### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_forecaster(data, cat, exog=[]):\n",
    "    \"\"\"\n",
    "    \n",
    "    Iterate over each day in the data and predict the next 96 values (1 Day)\n",
    "    \n",
    "    \"\"\"\n",
    "    all_predictions = pd.DataFrame(columns=[\"preds\"])\n",
    "    print(len(data))\n",
    "\n",
    "    for i in range(0, len(data), 96):\n",
    "        if i + seq_len + 97 < len(data): # if there is more data\n",
    "            step_prediction = pd.DataFrame(columns=[\"preds\"])\n",
    "            \n",
    "            # if there are exog variables\n",
    "            if len(exog) > 0: \n",
    "                step_prediction[\"preds\"] = cat.predict(\n",
    "                    steps=96,\n",
    "                    last_window=data.iloc[\n",
    "                        i : i + seq_len, data.columns.get_loc(\"S_TOT\")\n",
    "                    ],\n",
    "                    exog=exog,\n",
    "                )\n",
    "            # if there are no exog variables\n",
    "            else:\n",
    "                step_prediction[\"preds\"] = cat.predict(\n",
    "                    steps=96,\n",
    "                    last_window=data.iloc[\n",
    "                        i : i + seq_len, data.columns.get_loc(\"S_TOT\")\n",
    "                    ],\n",
    "                )\n",
    "            # apply datetime as index for merging the step prediction \n",
    "            # to to the data df (to have the relation S_TOT, Prediction)\n",
    "            step_prediction[\"datetime\"] = data.iloc[\n",
    "                i + seq_len + 1 : i + 97 + seq_len\n",
    "            ].index\n",
    "            all_predictions = pd.concat([all_predictions, step_prediction])\n",
    "\n",
    "    all_predictions = all_predictions.set_index(\"datetime\")\n",
    "    data[\"preds\"] = all_predictions[\"preds\"]\n",
    "    data.dropna(inplace=True)\n",
    "    data[\"preds\"] = data[\"preds\"].astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a59f0c",
   "metadata": {},
   "source": [
    "# 1. Train only on S_TOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8623f24",
   "metadata": {},
   "source": [
    "### 1.1 Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ecb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings: --impute --compensate-outliers, no scaling applied\n",
    "df = pd.read_pickle(\"../data/not_scaled/load.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e2c71f",
   "metadata": {},
   "source": [
    "### 1.1.1 Optional: Add Additional Features (results get worse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21614e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if used, add varaibles as exogenous during training (see train with autoencoder for reference)\n",
    "df[\"time\"] = df.index.strftime(\"%H\")\n",
    "df[\"month\"] = df.index.month\n",
    "df[\"min\"] = df.index.strftime(\"%M\")\n",
    "df[\"hour_min\"] = df[\"time\"] + df[\"min\"]\n",
    "df[\"weekday\"] = df.index.weekday\n",
    "df[\"hour_min\"] = df[\"hour_min\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af8bac",
   "metadata": {},
   "source": [
    "### 1.2 Select features for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfe369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df[[\"S_TOT\", \"hour_min\" ,\"date_is_holiday\", \"weekday\", \"date_season\"]]\n",
    "data = df[[\"S_TOT\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83f0f4",
   "metadata": {},
   "source": [
    "### 1.3 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db5b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.loc[\"2018-05-01 00:00:00+00:00\":\"2019-12-31 23:45:00+00:00 \"]\n",
    "data_test = data.loc[\"2019-12-31 23:45:00+00:00\":]\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d863c85",
   "metadata": {},
   "source": [
    "### 1.4 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf12ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use GPU instead of CPU use task_type=\"GPU\"\n",
    "seq_len = 2688\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=CatBoostRegressor(\n",
    "        iterations=1000, task_type=\"CPU\", grow_policy=\"Lossguide\", has_time=True\n",
    "    ),\n",
    "    lags=seq_len,\n",
    ")\n",
    "\n",
    "forecaster.fit(y=data_train[\"S_TOT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064daef",
   "metadata": {},
   "source": [
    "### 1.5 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68808c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step takes depending on the model size, data shape and window size up to 10 mins\n",
    "# since it's not possible to use a prediction intervall, every step has to be done separately\n",
    "prediction_df = predict_test_forecaster(data_test.copy(), forecaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a5388",
   "metadata": {},
   "source": [
    "### 1.6 Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4cf482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {mean_squared_error(prediction_df['S_TOT'], prediction_df['preds'], squared=False)}\")\n",
    "print(f\"RMSE: {mean_squared_error(prediction_df['S_TOT'], prediction_df['preds'])}\")\n",
    "print(f\"R2: {r2_score(prediction_df['S_TOT'], prediction_df['preds'])}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(prediction_df['S_TOT'], prediction_df['preds'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff159ab7",
   "metadata": {},
   "source": [
    "### 1.7 Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a1e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(prediction_df, x=prediction_df.index, y=[\"S_TOT\", \"preds\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319e1332",
   "metadata": {},
   "source": [
    "### 1.8 Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f15800",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "forecaster.get_feature_importance().sort_values(by=[\"importance\"], ascending=False)\n",
    "\n",
    "# The most important feature by far is the first value in the window size \n",
    "# (the last 15 min value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff4fff",
   "metadata": {},
   "source": [
    "### 1.9 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd69294",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(forecaster, filename=f\"gboost_model_{seq_len}.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b831b",
   "metadata": {},
   "source": [
    "# 2. Train with Autoencoder Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79ecef6",
   "metadata": {},
   "source": [
    "### 2.1 Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings: --impute --compensate-outliers, no scaling applied\n",
    "df = pd.read_pickle(\"../data/preprocessed_ae/load.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7320d0ee",
   "metadata": {},
   "source": [
    "### 2.2 Select Features for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"S_TOT\"] = df[\"TARGET\"].shift(-1)\n",
    "df.dropna(inplace=True)\n",
    "data = df.drop(\"TARGET\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a327d4",
   "metadata": {},
   "source": [
    "### 2.3 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e55a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.loc[\"2018-05-01 00:00:00+00:00\":\"2019-12-31 23:45:00+00:00 \"]\n",
    "data_test = data.loc[\"2019-12-31 23:45:00+00:00\":]\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\"\n",
    ")\n",
    "data_test_exog = data_test.drop(\"S_TOT\", axis=1)\n",
    "data_train_exog = data_train.drop(\"S_TOT\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d140610",
   "metadata": {},
   "source": [
    "### 2.4 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use GPU instead of CPU use task_type=\"GPU\"\n",
    "seq_len = 2688\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=CatBoostRegressor(\n",
    "        iterations=1000, task_type=\"CPU\", grow_policy=\"Lossguide\", has_time=True, \n",
    "    ),\n",
    "    lags=seq_len,\n",
    ")\n",
    "forecaster.fit(y=data_train[\"S_TOT\"], exog=data_train_exog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1ed88",
   "metadata": {},
   "source": [
    "### 2.5 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = predict_test_forecaster(data_test.copy(), forecaster, data_test_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e4013",
   "metadata": {},
   "source": [
    "### 2.6 Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a21528",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {mean_squared_error(prediction_df['S_TOT'], prediction_df['preds'], squared=False)}\")\n",
    "print(f\"RMSE: {mean_squared_error(prediction_df['S_TOT'], prediction_df['preds'])}\")\n",
    "print(f\"R2: {r2_score(prediction_df['S_TOT'], prediction_df['preds'])}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(prediction_df['S_TOT'], prediction_df['preds'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868c15b",
   "metadata": {},
   "source": [
    "### 2.7 Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547dec60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.line(prediction_df, x=prediction_df.index, y=[\"S_TOT\", \"preds\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e20ce",
   "metadata": {},
   "source": [
    "### 2.8 Check Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe2959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "forecaster.get_feature_importance().sort_values(by=[\"importance\"], ascending=False)\n",
    "\n",
    "\n",
    "# The most important feature by far is the first value in the window size \n",
    "# (the last 15 min value)\n",
    "\n",
    "\n",
    "# The features from the autoencoder are not that relevant, which matches the metric results as they are not that different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ebcca",
   "metadata": {},
   "source": [
    "### 2.9 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2622ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(forecaster, filename=f\"gboost_model_{seq_len}_ae.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003f8825",
   "metadata": {},
   "source": [
    "# 3. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f1c8e8",
   "metadata": {},
   "source": [
    "### 3.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/not_scaled/load.pkl\")\n",
    "\n",
    "data = df[[\"S_TOT\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179caa06",
   "metadata": {},
   "source": [
    "### 3.2 Train Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19413304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use GPU instead of CPU use task_type=\"GPU\"\n",
    "lags_grid = [96, 192, 672, 1344, 2016, 2688]\n",
    "cat = ForecasterAutoreg(\n",
    "    regressor=CatBoostRegressor(\n",
    "        iterations=20000,\n",
    "        task_type=\"CPU\",\n",
    "        verbose=False,\n",
    "        grow_policy=\"Lossguide\",\n",
    "        has_time=True,\n",
    "    ),\n",
    "    lags=seq_len,\n",
    ")\n",
    "# Regressor hyperparameters\n",
    "param_grid = {\n",
    "    \"iterations\": [500, 1000, 2000, 5000, 7000, 10000],\n",
    "    \"depth\": [16, 32, 64],\n",
    "    \"max_leaves\": [64, 128],\n",
    "    \"learning_rate\": [0.03, 0.1, 0.3],\n",
    "    \"reg_lambda\": [2, 3, 6],\n",
    "}\n",
    "results_grid = grid_search_forecaster(\n",
    "    forecaster=cat,\n",
    "    y=data.loc[\"2018-05-01 00:00:00+00:00\":\"2019-12-31 23:45:00+00:00\", \"S_TOT\"],\n",
    "    param_grid=param_grid,\n",
    "    lags_grid=lags_grid,\n",
    "    steps=96,\n",
    "    refit=False,\n",
    "    metric=\"mean_squared_error\",\n",
    "    initial_train_size=len(\n",
    "        data.loc[\"2018-05-01 00:00:00+00:00\":\"2019-05-01 23:45:00+00:00\"]\n",
    "    ),\n",
    "    fixed_train_size=False,\n",
    "    return_best=True,\n",
    "    verbose=False,\n",
    "    exog=None,  # can be changed to use multiple Features\n",
    ")\n",
    "\n",
    "# Notice, that initial_train_size limits the training size of the y data until 2019-05-01 23:45:00+00:00\n",
    "# so 2019-05-01 23:45:00+00:00 - 2019-12-31 23:45:00+00:00 is used for validation\n",
    "\n",
    "\n",
    "# the best results are from the model trained with:\n",
    "# depth=64\n",
    "# max_leaves=128\n",
    "# learning_rate=default\n",
    "# reg_lambda = default\n",
    "# lag=2688\n",
    "# iterations = 2000\n",
    "# Autoencoder features as exogenous variables\n",
    "\n",
    "# Metrics on testing dataset:\n",
    "# MSE around 4.6-4.8 mio\n",
    "# MAPE around 9.6 to 9.8 %\n",
    "# R2 around 0.72-0.74\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95685fe9",
   "metadata": {},
   "source": [
    "### 3.3 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = predict_test_forecaster(data_test.copy(), cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5863279c",
   "metadata": {},
   "source": [
    "### 3.4 Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a79174",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE: {mean_squared_error(prediction_df['S_TOT'], prediction_df['preds'], squared=False)}\")\n",
    "print(f\"RMSE: {mean_squared_error(prediction_df['S_TOT'], prediction_df['preds'])}\")\n",
    "print(f\"R2: {r2_score(prediction_df['S_TOT'], prediction_df['preds'])}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(prediction_df['S_TOT'], prediction_df['preds'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c827c7",
   "metadata": {},
   "source": [
    "### 3.5 Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd6656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(prediction_df, x=prediction_df.index, y=[\"S_TOT\", \"preds\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd8a4c",
   "metadata": {},
   "source": [
    "### 3.6 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545904ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(cat, filename=\"gboost_model_grid.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2be816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfecc32a",
   "metadata": {},
   "source": [
    "# How to use a Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6cb31",
   "metadata": {},
   "source": [
    "### Only S_TOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90647959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecaster = load(\"./boosting_models/gboost_model_2688.py\")\n",
    "# Settings: --impute --compensate-outliers, no scaling applied\n",
    "df = pd.read_pickle(\"../data/not_scaled/load.pkl\")\n",
    "seq_len = 2688\n",
    "data = df[[\"S_TOT\"]]\n",
    "\n",
    "data_train = data.loc[\"2018-05-01 00:00:00+00:00\":\"2019-12-31 23:45:00+00:00 \"]\n",
    "data_test = data.loc[\"2019-12-31 23:45:00+00:00\":]\n",
    "data_test[\"date\"] = data_test.index\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\"\n",
    ")\n",
    "\n",
    "prediction_df = predict_test_forecaster(data_test.copy(), forecaster)\n",
    "\n",
    "fig = px.line(prediction_df, x=prediction_df.index, y=[\"S_TOT\", \"preds\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb826a1f",
   "metadata": {},
   "source": [
    "### Autoencoder Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8859701",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = load(\"./boosting_models/gboost_model_2688_ae.py\")\n",
    "# Settings: --impute --compensate-outliers, no scaling applied\n",
    "df = pd.read_pickle(\"../data/preprocessed_ae/load.pkl\")\n",
    "\n",
    "df[\"S_TOT\"] = df[\"TARGET\"].shift(-1)\n",
    "df.dropna(inplace=True)\n",
    "data = df.drop(\"TARGET\", axis=1)\n",
    "\n",
    "data_train = data.loc[\"2018-05-01 00:00:00+00:00\":\"2019-12-31 23:45:00+00:00 \"]\n",
    "data_test = data.loc[\"2019-12-31 23:45:00+00:00\":]\n",
    "\n",
    "print(\n",
    "    f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\"\n",
    ")\n",
    "print(\n",
    "    f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\"\n",
    ")\n",
    "data_test_exog = data_test.drop(\"S_TOT\", axis=1)\n",
    "\n",
    "prediction_df = predict_test_forecaster(data_test.copy(), forecaster, data_test_exog)\n",
    "\n",
    "fig = px.line(prediction_df, x=prediction_df.index, y=[\"S_TOT\", \"preds\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68179fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
