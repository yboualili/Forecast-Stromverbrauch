{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yw6RzGLbudiq"
   },
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# do local imports\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.models.autoencoder import Autoencoder\n",
    "from src.model_selection.objective import AEObjective, split_train_test\n",
    "from src.optim.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"\"\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    root_path = \"/content/drive/MyDrive/data/\"\n",
    "else:\n",
    "    root_path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "LvQjAEVcudis",
    "outputId": "7f7ef7ca-2d1f-417f-825c-95f431bb9633"
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle(f\"{root_path}preprocessed/load.pkl\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjRSMJrfudiv"
   },
   "outputs": [],
   "source": [
    "features = data.columns.to_list()\n",
    "\n",
    "# remove target from features and save to separate df\n",
    "X = data[features]\n",
    "y = data[[\"S_TOT\"]]\n",
    "# convert to series\n",
    "y = y.iloc[:, 0]\n",
    "\n",
    "X_train, y_train, X_val, y_val, _, _ = split_train_test(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2048\n",
    "batch_size = 1024\n",
    "lr = 3e-4\n",
    "bottleneck_capacity = 64\n",
    "num_layers = 3\n",
    "dropout = 0.5\n",
    "activation = \"ReLU\"\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "dataset_train = TensorDataset(Tensor(X_train.astype(np.float32).values))\n",
    "dataset_val = TensorDataset(Tensor(X_val.astype(np.float32).values))\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load model to device\n",
    "model = Autoencoder(\n",
    "    num_features=num_features,\n",
    "    bottleneck_capacity=bottleneck_capacity,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    activation=activation,\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# keep track of val loss and do early stopping\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    loss_in_epoch_train = 0\n",
    "\n",
    "    # perform training\n",
    "    model.train()\n",
    "    for batch_features in train_loader:\n",
    "\n",
    "        # reshape mini-batch data to [N, [X.shape[1]] matrix\n",
    "        batch_features = batch_features[0].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, _ = model(batch_features)\n",
    "        train_loss = loss(outputs, batch_features)\n",
    "\n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "\n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss_in_epoch_train += train_loss.item()\n",
    "\n",
    "        # Validation of the model e. g., disable Dropout when testing\n",
    "        model.eval()\n",
    "\n",
    "    loss_in_epoch_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_features in val_loader:\n",
    "            # reshape mini-batch data to [N, [X.shape[1]] matrix\n",
    "            batch_features = batch_features[0].to(device)\n",
    "            outputs, _ = model(batch_features)\n",
    "\n",
    "            test_loss = loss(outputs, batch_features)\n",
    "            loss_in_epoch_test += test_loss.item()\n",
    "\n",
    "    train_loss = loss_in_epoch_train / len(train_loader)\n",
    "    test_loss = loss_in_epoch_test / len(val_loader)\n",
    "\n",
    "    # return early if test loss doesn't decrease for several iterations\n",
    "    early_stopping(test_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        break\n",
    "\n",
    "    print(f\"epoch : {epoch + 1}/{epochs},\", end=\" \")\n",
    "    print(f\"loss (train) = {train_loss:.8f}, loss (test) = {test_loss:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian search\n",
    "Bayesian search build on top of [optuna](https://optuna.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POX8qM7tuWug",
    "outputId": "9509a239-54ce-4a49-881a-340643e6d3a8"
   },
   "outputs": [],
   "source": [
    "N_TRIALS = 64\n",
    "name = \"load_outlier\"\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "objective = AEObjective(X, y, name)\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "optimized_params = study.best_trial.params\n",
    "print(f\"params: {optimized_params}\")\n",
    "print(f\"no: {study.best_trial.number}\")\n",
    "study_all_trails = study.trials_dataframe()\n",
    "study_all_trails.to_csv(f\"../docs/study_AE_{name}_all_parameters.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8GVgcUwYJZm5",
    "outputId": "7dea03a3-b8b9-4b33-b545-1fdb5b5b4ff0"
   },
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "optuna.visualization.matplotlib.plot_slice(study)\n",
    "optuna.visualization.matplotlib.plot_contour(\n",
    "    study,\n",
    "    [\"lr\", \"batch_size\", \"num_layers\", \"bottleneck_capacity\", \"activation\", \"dropout\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scM7vpU9uWui",
    "outputId": "9df30359-3c74-470d-cb67-9ecfb3d81c67"
   },
   "outputs": [],
   "source": [
    "# overwrite manually if needed\n",
    "no_trial = study.best_trial.number\n",
    "num_layers_trial = optimized_params.get(\"num_layers\")\n",
    "bottleneck_capacity_trial = optimized_params.get(\"bottleneck_capacity\")\n",
    "dropout_trial = optimized_params.get(\"dropout\")\n",
    "batch_size_trial = optimized_params.get(\"batch_size\")\n",
    "activation_trial = optimized_params.get(\"activation\")\n",
    "\n",
    "model = Autoencoder(\n",
    "    num_features=X.shape[1],\n",
    "    num_layers=num_layers_trial,\n",
    "    bottleneck_capacity=bottleneck_capacity_trial,\n",
    "    dropout=dropout_trial,\n",
    "    activation=activation_trial,\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(f\"../models/{model.__class__.__name__}_{name}_trial_{no_trial}.pth\")\n",
    ")\n",
    "model.eval()\n",
    "encoder = model.encoder\n",
    "print(encoder)\n",
    "\n",
    "# process entire dataset\n",
    "dataset_full = TensorDataset(Tensor(X.astype(np.float32).values))\n",
    "full_loader = DataLoader(dataset_full, batch_size=batch_size_trial, shuffle=False)\n",
    "\n",
    "low_dim = []\n",
    "\n",
    "for batch_features in full_loader:\n",
    "    latent = encoder(batch_features[0])\n",
    "    low_dim.append(latent.detach().cpu().numpy())\n",
    "\n",
    "X_low_dim = pd.DataFrame(np.concatenate(low_dim), index=X.index)\n",
    "X_low_dim = X_low_dim.add_prefix(\"pc_\")\n",
    "\n",
    "# add original target back to data set\n",
    "X_low_dim[\"S_TOT\"] = y\n",
    "\n",
    "X_low_dim.to_pickle(f\"../data/preprocessed/{name}_low_dim.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "01_model_building.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "metadata": {
   "interpreter": {
    "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
   }
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d0eb90d806cd3776b487bfccd63e3b11941e37b69aec4019d7ae76513bb84d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}